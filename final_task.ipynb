{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab2b1e19-1fd3-4319-8cc3-585473cf568a",
   "metadata": {},
   "source": [
    "## DS4DS Final Task:\n",
    "\n",
    "Upload your solution (training pipeline and final model ready for inference) as one archive file (.zip) to moodle at least three days prior to your exam appointments. Request an appointment at least two weeks in advance via email (oliver.wallscheid@uni-siegen.de). The latest exam date will be by end of September 2025. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6bcac",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa7c12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Weave\n",
    "weave(\"final_task.ipynb\", out_path=\"errorfree1.html\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e4c24d1-0e11-4b63-9abe-0f48972f8af9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `d:\\ds4dsproject\\final_task_data_and_aux_files\\final_task`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mStatus\u001b[22m\u001b[39m `D:\\ds4dsproject\\final_task_data_and_aux_files\\final_task\\Project.toml` (empty project)\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\".\")\n",
    "Pkg.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341ea364-78bf-402a-87da-b833f9fe061b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this might take a few minutes, but you should only need to do this once\n",
    "# when you use the project for the first time\n",
    "Pkg.precompile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b36555d-afa1-46f3-ab6e-48517fa829b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using MAT\n",
    "using Plots \n",
    "using LaTeXStrings\n",
    "using Serialization\n",
    "using StatsBase\n",
    "using Flux\n",
    "\n",
    "include(\"utils.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c192bb-0fc6-4a6b-9e4a-9208c15a92e0",
   "metadata": {},
   "source": [
    "### Thermal modelling of an electric vehicle motor\n",
    "\n",
    "Your task is to create a model for the thermal dynamics of an electric motor.\n",
    "More formally, you need to find a parameterized model of the form\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\frac{\\mathrm{d}}{\\mathrm{d}t} \\mathbf{x}(t) &= \\mathcal{M}_\\mathbf{w} (\\mathbf{x}(t), \\mathbf{u}(t)) \\\\\n",
    "    \\mathbf{y}(t) & = \\mathbf{x} (t)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{x}(t)$ the state of the system and $\\mathbf{u(t)}$ is the input vector. The state and\n",
    "input signals are described further into this notebook. There are no boundaries on the specific model class and topology regarding $\\mathcal{M}_\\mathbf{w}$, that is, you are allowed to investigate freely which modelling approaches are suitable.\n",
    "\n",
    "You will be given a dataset which you can use to train/fit your model. After submission, we will evaluate your model\n",
    "on a different portion of the dataset to see its generalization performance.\n",
    "This evaluation will be done by comparing state trajectories predicted by your model $\\hat{\\mathbf{X}}_i$ with the\n",
    "true trajectory $\\mathbf{X}_i$ using the mean squared error (MSE). The estimate $\\hat{\\mathbf{X}}_i$ is to be calculated \n",
    "based on an initial true state $\\mathbf{x}_{0,i}$ (which is the first element of $\\mathbf{X}_i$) and the true inputs \n",
    "$\\mathbf{U}_i$ (or an interpolation of the true inputs). This means that your task is to build a simulation model that produces the state trajectory based on the\n",
    "initial state and inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77858f3a-53c5-40b8-ab2e-e954f8cd91d6",
   "metadata": {},
   "source": [
    "**Considered grading criteria:**\n",
    "\n",
    "- functional and tidy codebase\n",
    "- successful inference on test set (no errors)\n",
    "- model and feature innovations/concepts (beyond bare-bone black-box models)\n",
    "- final presentation of proposed solution and used modeling rationale\n",
    "- model accuracy (MSE) on unseen/hidden test data (not part of this folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89edbca-dca6-48cc-a6a5-85d1b75fec01",
   "metadata": {},
   "source": [
    "### Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9af8d451-0ca3-490c-82e3-2ef70ddc1050",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, Any} with 6 entries:\n",
       "  \"XNames\"             => Any[\"TpStatTc\" \"TpRotTc\"]\n",
       "  \"U\"                  => [500.01 0.38556 … 59.46 61.18; 500.02 0.392385 … 59.4…\n",
       "  \"X\"                  => [65.402 67.427; 65.3795 67.4218; … ; 81.6888 86.2227;…\n",
       "  \"measurement_series\" => [1; 1; … ; 10; 10;;]\n",
       "  \"dt\"                 => 0.5\n",
       "  \"UNames\"             => Any[\"NSft\" \"TqSftClcdInv\" … \"TpOilRotRetA\" \"TpOilRotR…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = matread(\"train_data.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e67c8d9-5e8d-4436-9319-ad6a317c378f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract data from dict\n",
    "\n",
    "U = data[\"U\"];\n",
    "X = data[\"X\"];\n",
    "Y = X;\n",
    "\n",
    "UNames = data[\"UNames\"];\n",
    "XNames = data[\"XNames\"];\n",
    "YNames = XNames;\n",
    "\n",
    "measurement_series = data[\"measurement_series\"];\n",
    "dt = data[\"dt\"];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc40d3c-fa9d-493e-bcc3-f02d5db48d30",
   "metadata": {},
   "source": [
    "### Data description:\n",
    "\n",
    "You are given a part of a dataset measured from an electric motor at Mercedes-Benz to examine its thermal properties. The dataset you are given consists of $594885$ measurement points, which are divided into $10$ independent series of measurement sessions. A short description of the different variables in the data is given in the following:\n",
    "\n",
    "---\n",
    "\n",
    "- ```data[\"U\"]``` contains a matrix with the shape $594885 \\times 21$. These are the $594885$ samples of the input vector $\\mathbf{u}(t) \\in \\mathbb{R}^{21}$ which can influence its thermal behavior. In detail these are\n",
    "    - $u_1$: rpm, rotations per minute of the motor shaft\n",
    "    - $u_2$: torque of the drive shaft\n",
    "    - $u_3$: absolute value of the torque of the drive shaft\n",
    "    - $u_4$: $i_d$ d-current\n",
    "    - $u_5$: $i_q$ q-current\n",
    "    - $u_6$: $\\| i_q \\|$\n",
    "    - $u_7$: root-mean-squared phase current\n",
    "    - $u_8$: $u_d$ d-voltage\n",
    "    - $u_{9}$: $\\| u_d \\|$ \n",
    "    - $u_{10}$: $u_q$ q-voltage\n",
    "    - $u_{11}$: neutral point displacement voltage\n",
    "    - $u_{12}$: inverter switching frequency\n",
    "    - $u_{13}$: DC link voltage\n",
    "    - $u_{14}$: modulation index\n",
    "    - $u_{15}$: power of the drive shaft\n",
    "    - $u_{16}$: oil flow rate for cooling of the rotor\n",
    "    - $u_{17}$: oil flow rate for cooling of the stator\n",
    "    - $u_{18}$: oil temperature at entry (rotor)\n",
    "    - $u_{19}$: oil temperature at entry (stator)\n",
    "    - $u_{20}$: oil temperature at exit A (rotor)\n",
    "    - $u_{21}$: oil temperature at exit B (rotor)\n",
    "- ```data[\"UNames\"]``` contains abbreviations for the different elements in $\\mathbf{u}(t)$, e.g. for plot labels\n",
    "- ```data[\"X\"]``` contains the state of the motor, which in this case is a stator and a rotor temperature. There are $594885$ samples of the state vector (target) $\\mathbf{x}(t) \\in \\mathbb{R}^{2}$.\n",
    "    - $x_1$: $T_{stat}$ stator temperature\n",
    "    - $x_2$: $T_{rot}$ rotor temperature\n",
    "- ```data[\"XNames\"]``` contains abbreviations for the different elements in $\\mathbf{x}(t)$, e.g. for plot labels\n",
    "- ```data[\"dt\"]``` contains the time between measurement points\n",
    "- ```data[\"measurement_series\"]``` contains a matrix with the shape $594885 \\times 1$. That assigns each measurement point to a measurement series, i.e. the $242856$-th element in this matrix is a $4$ which means that the $242856$-th measurement belongs to measurement series $4$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bc69f7-1b51-4087-95ad-6e990f959b56",
   "metadata": {},
   "source": [
    "**Hint 1:** What implication does the split into multiple measurement series have? Does it make sense to use all of the data at once?\n",
    "\n",
    "**Hint 2:** While you might not have access to the actual test data, is there a way to improve/test the generalization performance of your model?\n",
    "\n",
    "**Hint 3:** Through the  ```utils.jl```-file in the task folder you are given a set of minimal helper functions which you can use to get a feeling for the data and create some plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a84cbd-9ec7-4420-bc1e-ba5824dc8161",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "?plot_at_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fc42a7-0a29-475e-8022-5d0ed0117c8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p1 = plot(xlabel=L\"k\", ylabel=L\"u\");\n",
    "p1 = plot_at_idx(p1, U, measurement_series, UNames, measurement_series_idx=4, feature_idx=21) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e46eb9b-4c55-4f63-a2dc-de40242c746f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p2 = plot(xlabel=L\"k\", ylabel=L\"y\");\n",
    "p2 = plot_at_idx(p2, Y, measurement_series, XNames, measurement_series_idx=8, feature_idx=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af707d42-4e9d-4d59-89bb-c642ad3c7530",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p = plot_histogram(U, UNames, feature_idx=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c063f5b7-c2fa-473d-a4e9-58abc3f79a8f",
   "metadata": {},
   "source": [
    "### Create and fit your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577f4b23-04b6-41b0-b701-bfc19e43b1f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# REPLACE WITH YOUR CODE\n",
    "parameters = [2, 2, 5, 1]-\n",
    "\n",
    "if @isdefined parameters\n",
    "    serialize(\"final_task_parameters\", parameters)\n",
    "end\n",
    "# REPLACE WITH YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adc40cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_prep (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#functions for feature engg and data prep\n",
    "function feature_engg(u)\n",
    "    return u\n",
    "end\n",
    "\n",
    "function data_prep(U_raw, X_raw, measurement_series, series_indices)\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for series_idx in series_indices\n",
    "        u_series = extract(U_raw, measurement_series, series_idx)\n",
    "        x_series = extract(X_raw, measurement_series, series_idx)\n",
    "\n",
    "        u_series = Float32.(u_series)\n",
    "        x_series = Float32.(x_series)\n",
    "\n",
    "        engineered_u = feature_engg(u_series)\n",
    "\n",
    "        input_data = permutedims(engineered_u, (2, 1))\n",
    "        target_data = permutedims(x_series, (2, 1))\n",
    "\n",
    "        push!(inputs, input_data)\n",
    "        push!(targets, target_data)\n",
    "    end\n",
    "    return inputs, targets\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b85cddc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Any[Float32[499.98 500.01 … 499.94 499.93002; 0.38744998 0.38839498 … 0.38450998 0.38682; … ; 74.67 74.67 … 55.316 55.278; 75.76 75.76 … 55.176003 55.128002], Float32[499.92 500.1 … 500.02 499.99; 0.38913 0.39753 … 0.37611002 0.39732; … ; 55.24 55.19 … 76.72 76.72; 55.08 55.05 … 79.13 79.13]], Any[Float32[77.68367 77.67987 … 69.89871 69.900276; 83.07999 83.08416 … 85.300865 85.26539], Float32[69.90183 69.90491 … 81.68883 81.68314; 85.22991 85.18944 … 86.22274 86.21673]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_series_indices = 1\n",
    "val_series_indices = 6:8\n",
    "test_series_indices = 9:10\n",
    "\n",
    "# 1. First, get all data\n",
    "training_inputs, training_targets = data_prep(U, X, measurement_series, training_series_indices)\n",
    "val_inputs, val_targets = data_prep(U, X, measurement_series, val_series_indices)\n",
    "test_inputs, test_targets = data_prep(U, X, measurement_series, test_series_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f75011b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Any[Float32[499.98 500.01 … 499.94 499.93002; 0.38744998 0.38839498 … 0.38450998 0.38682; … ; 74.67 74.67 … 55.316 55.278; 75.76 75.76 … 55.176003 55.128002], Float32[499.92 500.1 … 500.02 499.99; 0.38913 0.39753 … 0.37611002 0.39732; … ; 55.24 55.19 … 76.72 76.72; 55.08 55.05 … 79.13 79.13]], Any[Float32[77.68367 77.67987 … 69.89871 69.900276; 83.07999 83.08416 … 85.300865 85.26539], Float32[69.90183 69.90491 … 81.68883 81.68314; 85.22991 85.18944 … 86.22274 86.21673]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This function calculates the maximum features across all data sets\n",
    "function find_max_features(all_inputs, all_targets)\n",
    "    max_input = 0\n",
    "    for inputs in all_inputs\n",
    "        max_input = max(max_input, maximum(size(i, 1) for i in inputs))\n",
    "    end\n",
    "    max_target = 0\n",
    "    for targets in all_targets\n",
    "        max_target = max(max_target, maximum(size(t, 1) for t in targets))\n",
    "    end\n",
    "    return max_input, max_target\n",
    "end\n",
    "\n",
    "# This function pads a single data set to the given max features\n",
    "function pad_to_fixed_features(inputs, targets, max_input_features, max_target_features)\n",
    "    padded_inputs = []\n",
    "    padded_targets = []\n",
    "\n",
    "    for (inp, tgt) in zip(inputs, targets)\n",
    "        # Pad inputs with zeros\n",
    "        if size(inp, 1) < max_input_features\n",
    "            padding = zeros(Float32, max_input_features - size(inp, 1), size(inp, 2))\n",
    "            padded_inp = vcat(inp, padding)\n",
    "        else\n",
    "            padded_inp = inp\n",
    "        end\n",
    "\n",
    "        # Pad targets with zeros\n",
    "        if size(tgt, 1) < max_target_features\n",
    "            padding = zeros(Float32, max_target_features - size(tgt, 1), size(tgt, 2))\n",
    "            padded_tgt = vcat(tgt, padding)\n",
    "        else\n",
    "            padded_tgt = tgt\n",
    "        end\n",
    "\n",
    "        push!(padded_inputs, padded_inp)\n",
    "        push!(padded_targets, padded_tgt)\n",
    "    end\n",
    "    return padded_inputs, padded_targets\n",
    "end\n",
    "\n",
    "training_series_indices = 1:5\n",
    "val_series_indices = 6:8\n",
    "test_series_indices = 9:10\n",
    "\n",
    "# 1. First, get all data\n",
    "training_inputs, training_targets = data_prep(U, X, measurement_series, training_series_indices)\n",
    "val_inputs, val_targets = data_prep(U, X, measurement_series, val_series_indices)\n",
    "test_inputs, test_targets = data_prep(U, X, measurement_series, test_series_indices)\n",
    "\n",
    "# 2. Find the global max features across all data sets\n",
    "max_input_features, max_target_features = find_max_features(\n",
    "    [training_inputs, val_inputs, test_inputs],\n",
    "    [training_targets, val_targets, test_targets]\n",
    ")\n",
    "\n",
    "# 3. Pad all data sets using the global max features\n",
    "training_inputs, training_targets = pad_to_fixed_features(training_inputs, training_targets, max_input_features, max_target_features)\n",
    "val_inputs, val_targets = pad_to_fixed_features(val_inputs, val_targets, max_input_features, max_target_features)\n",
    "test_inputs, test_targets = pad_to_fixed_features(test_inputs, test_targets, max_input_features, max_target_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5552280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique(size(x, 1) for x in training_inputs)\n",
    "println(\"Training data shapes:\")\n",
    "for i in 1:length(training_inputs)\n",
    "    println(\"Sample $i: input size = \", size(training_inputs[i]), \", target size = \", size(training_targets[i]))\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8020096a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = training_inputs[1]\n",
    "sample_target = training_targets[1]\n",
    "\n",
    "println(\"Sample input size: \", size(sample_input))\n",
    "println(\"Sample target size: \", size(sample_target))\n",
    "\n",
    "Flux.reset!(model)\n",
    "output = model(sample_input[:, 1:2])  # Forward pass on first 2 timesteps\n",
    "\n",
    "println(\"Model output size: \", size(output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56efcd39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluate_model (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Flux, Flux.Optimise\n",
    "using Flux: params\n",
    "\n",
    "#model\n",
    "num_input_features = size(training_inputs[1], 1)\n",
    "num_output_features = size(training_targets[1], 1)\n",
    "\n",
    "hidden_size = 64\n",
    "model = Chain(\n",
    "    LSTM(num_input_features => hidden_size), \n",
    "    Dense(hidden_size, num_output_features)\n",
    ")\n",
    "\n",
    "#loss\n",
    "mse(predicted, target) = mean(abs2, predicted .- target)\n",
    "\n",
    "#optimizer\n",
    "optimizer = Flux.setup(ADAM(), model)\n",
    "\n",
    "#eval\n",
    "function evaluate_model(model, inputs, targets)\n",
    "    total_loss = 0.0\n",
    "    for (input, target) in zip(inputs, targets)\n",
    "        Flux.reset!(model)\n",
    "\n",
    "        len = min(size(input, 2), size(target, 2))\n",
    "\n",
    "        model(reshape(input[:, 1], :, 1))\n",
    "        predicted_traj = []\n",
    "\n",
    "        for t in 2:len\n",
    "            prediction = model(reshape(input[:, t], :, 1))\n",
    "            push!(predicted_traj, prediction)\n",
    "        end\n",
    "        predicted_traj = hcat(predicted_traj...)\n",
    "\n",
    "        prediction_targets = target[:, 2:len]\n",
    "        total_loss += mse(predicted_traj, prediction_targets)\n",
    "    end\n",
    "    return total_loss/length(inputs)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb97837",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "epochs = 10\n",
    "for epoch in 1:epochs\n",
    "    for (inputs, targets) in zip(training_inputs, training_targets)\n",
    "        Flux.reset!(model)\n",
    "\n",
    "        loss_function() = begin\n",
    "            len = min(size(inputs, 2), size(targets, 2))\n",
    "\n",
    "            # The first time step is used to set the initial state.\n",
    "            model(reshape(inputs[:, 1], :, 1))\n",
    "\n",
    "            # This line uses a non-mutating list comprehension to build the trajectory.\n",
    "            predicted_traj = hcat([model(reshape(inputs[:, t], :, 1)) for t in 2:len]...)\n",
    "\n",
    "            # The commented-out code below caused the \"Mutating arrays\" error.\n",
    "            # predicted_traj = []\n",
    "            # for t in 2:len\n",
    "            #     prediction = model(reshape(inputs[:, t], :, 1))\n",
    "            #     push!(predicted_traj,prediction)\n",
    "            # end\n",
    "            # predicted_traj = hcat(predicted_traj...)\n",
    "\n",
    "            prediction_targets = targets[:, 2:len]\n",
    "            mse(predicted_traj, prediction_targets)\n",
    "        end\n",
    "        \n",
    "        loss, back = Flux.pullback(model -> loss_function(), model)\n",
    "        grads = back(1f0)\n",
    "        optimizer, model = Optimisers.update(optimizer, model, grads[1])\n",
    "    end\n",
    "\n",
    "    train_loss = evaluate_model(model, training_inputs, training_targets)\n",
    "    validation_loss = evaluate_model(model, val_inputs, val_targets)\n",
    "    \n",
    "    println(\"Epoch $epoch, Training Loss: $train_loss, Validation Loss: $validation_loss\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a372e097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrected training loop\n",
    "epochs = 10\n",
    "for epoch in 1:epochs\n",
    "    for (inputs, targets) in zip(training_inputs, training_targets)\n",
    "        # Reset the model's state at the start of each new sequence\n",
    "        Flux.reset!(model)\n",
    "\n",
    "        loss_function() = begin\n",
    "            # Pass the entire sequence to the model at once\n",
    "            predicted_traj = model(inputs)\n",
    "            \n",
    "            # Since the model returns the output for all timesteps,\n",
    "            # you can compare it directly with the targets.\n",
    "            mse(predicted_traj, targets)\n",
    "        end\n",
    "        \n",
    "        loss, back = Flux.pullback(model -> loss_function(), model)\n",
    "        grads = back(1f0)\n",
    "        optimizer, model = Optimisers.update(optimizer, model, grads[1])\n",
    "    end\n",
    "\n",
    "    train_loss = evaluate_model(model, training_inputs, training_targets)\n",
    "    validation_loss = evaluate_model(model, val_inputs, val_targets)\n",
    "    \n",
    "    println(\"Epoch $epoch, Training Loss: $train_loss, Validation Loss: $validation_loss\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d351d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = model\n",
    "\n",
    "test_loss = evaluate_model(final_model, test_inputs, test_targets)\n",
    "println(\"Final test Loss: $test_loss\")\n",
    "\n",
    "serialize(\"final_task_parameters\", params(final_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb93b368-0665-45fc-a72c-80a370dcaec5",
   "metadata": {},
   "source": [
    "### Saving your model for evaluation:\n",
    "\n",
    "After you have finished your model, we will evaluate its performance on the test dataset. To do so we will need to be able to make a forward pass with your model and we will need you to give us your model parameters.\n",
    "\n",
    "- fill out the function given in ```model_forward_pass.jl```\n",
    "- store your parameters in a file named ```final_task_parameters```\n",
    "\n",
    "```\n",
    "# Example code for storing parameters:\n",
    "\n",
    "if @isdefined parameters\n",
    "    serialize(\"final_task_parameters\", parameters)\n",
    "end\n",
    "```\n",
    "\n",
    "You can use the code below on the training to check if your result can be read properly **(If you run into problems with this or if your forward pass needs extra inputs, please contact us)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3f9fe7-0072-416d-8862-6575b588a7f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "include(\"model_forward_pass.jl\");\n",
    "using .ModelForwardPass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ca0ee1-875d-4ae8-bb8d-d7178374cb7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "?ModelForwardPass.your_model_forward_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3598ff1-48bd-4cd3-87b6-6c94d46e09d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters_evaluation = deserialize(\"final_task_parameters\");\n",
    "\n",
    "measurement_series_idx = 1\n",
    "\n",
    "_u = extract(U, measurement_series, measurement_series_idx);\n",
    "_target = extract(X, measurement_series, measurement_series_idx);\n",
    "_x0 = _target[1, :];\n",
    "\n",
    "tsteps = collect(0:0.5:(size(_u, 1) * 0.5));\n",
    "\n",
    "predicted_trajectory = ModelForwardPass.your_model_forward_pass(\n",
    "    inputs=_u,\n",
    "    x0=_x0,\n",
    "    parameters=parameters_evaluation,\n",
    "    tsteps=tsteps\n",
    ");\n",
    "\n",
    "println(\"MSE: \", StatsBase.mean((_target - predicted_trajectory).^2))\n",
    "\n",
    "p_eval = plot(xlabel=L\"k\", ylabel=L\"x\")\n",
    "\n",
    "p_eval = plot_at_idx(p_eval, X, measurement_series, XNames, measurement_series_idx=measurement_series_idx, feature_idx=1)\n",
    "p_eval = plot!(p_eval, predicted_trajectory[:, 1], label=L\"\\hat{x}_1\")\n",
    "\n",
    "display(p_eval)\n",
    "\n",
    "p_eval = plot(xlabel=L\"k\", ylabel=L\"x\")\n",
    "\n",
    "p_eval = plot_at_idx(p_eval, X, measurement_series, XNames, measurement_series_idx=measurement_series_idx, feature_idx=2)\n",
    "p_eval = plot!(p_eval, predicted_trajectory[:, 2], label=L\"\\hat{x}_2\")\n",
    "\n",
    "display(p_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3cf9a9-c00b-4e5a-9d01-f453aae9b421",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.0",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
