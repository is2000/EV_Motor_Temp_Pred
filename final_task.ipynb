{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab2b1e19-1fd3-4319-8cc3-585473cf568a",
   "metadata": {},
   "source": [
    "## DS4DS Final Task:\n",
    "\n",
    "Upload your solution (training pipeline and final model ready for inference) as one archive file (.zip) to moodle at least three days prior to your exam appointments. Request an appointment at least two weeks in advance via email (oliver.wallscheid@uni-siegen.de). The latest exam date will be by end of September 2025. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6bcac",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa7c12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Weave\n",
    "weave(\"final_task.ipynb\", out_path=\"errorfree1.html\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e4c24d1-0e11-4b63-9abe-0f48972f8af9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `d:\\ds4dsproject\\final_task_data_and_aux_files\\final_task`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mStatus\u001b[22m\u001b[39m `D:\\ds4dsproject\\final_task_data_and_aux_files\\final_task\\Project.toml` (empty project)\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\".\")\n",
    "Pkg.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341ea364-78bf-402a-87da-b833f9fe061b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this might take a few minutes, but you should only need to do this once\n",
    "# when you use the project for the first time\n",
    "Pkg.precompile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b36555d-afa1-46f3-ab6e-48517fa829b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using MAT\n",
    "using Plots \n",
    "using LaTeXStrings\n",
    "using Serialization\n",
    "using StatsBase\n",
    "using Flux\n",
    "\n",
    "include(\"utils.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c192bb-0fc6-4a6b-9e4a-9208c15a92e0",
   "metadata": {},
   "source": [
    "### Thermal modelling of an electric vehicle motor\n",
    "\n",
    "Your task is to create a model for the thermal dynamics of an electric motor.\n",
    "More formally, you need to find a parameterized model of the form\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\frac{\\mathrm{d}}{\\mathrm{d}t} \\mathbf{x}(t) &= \\mathcal{M}_\\mathbf{w} (\\mathbf{x}(t), \\mathbf{u}(t)) \\\\\n",
    "    \\mathbf{y}(t) & = \\mathbf{x} (t)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{x}(t)$ the state of the system and $\\mathbf{u(t)}$ is the input vector. The state and\n",
    "input signals are described further into this notebook. There are no boundaries on the specific model class and topology regarding $\\mathcal{M}_\\mathbf{w}$, that is, you are allowed to investigate freely which modelling approaches are suitable.\n",
    "\n",
    "You will be given a dataset which you can use to train/fit your model. After submission, we will evaluate your model\n",
    "on a different portion of the dataset to see its generalization performance.\n",
    "This evaluation will be done by comparing state trajectories predicted by your model $\\hat{\\mathbf{X}}_i$ with the\n",
    "true trajectory $\\mathbf{X}_i$ using the mean squared error (MSE). The estimate $\\hat{\\mathbf{X}}_i$ is to be calculated \n",
    "based on an initial true state $\\mathbf{x}_{0,i}$ (which is the first element of $\\mathbf{X}_i$) and the true inputs \n",
    "$\\mathbf{U}_i$ (or an interpolation of the true inputs). This means that your task is to build a simulation model that produces the state trajectory based on the\n",
    "initial state and inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77858f3a-53c5-40b8-ab2e-e954f8cd91d6",
   "metadata": {},
   "source": [
    "**Considered grading criteria:**\n",
    "\n",
    "- functional and tidy codebase\n",
    "- successful inference on test set (no errors)\n",
    "- model and feature innovations/concepts (beyond bare-bone black-box models)\n",
    "- final presentation of proposed solution and used modeling rationale\n",
    "- model accuracy (MSE) on unseen/hidden test data (not part of this folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89edbca-dca6-48cc-a6a5-85d1b75fec01",
   "metadata": {},
   "source": [
    "### Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9af8d451-0ca3-490c-82e3-2ef70ddc1050",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, Any} with 6 entries:\n",
       "  \"XNames\"             => Any[\"TpStatTc\" \"TpRotTc\"]\n",
       "  \"U\"                  => [500.01 0.38556 … 59.46 61.18; 500.02 0.392385 … 59.4…\n",
       "  \"X\"                  => [65.402 67.427; 65.3795 67.4218; … ; 81.6888 86.2227;…\n",
       "  \"measurement_series\" => [1; 1; … ; 10; 10;;]\n",
       "  \"dt\"                 => 0.5\n",
       "  \"UNames\"             => Any[\"NSft\" \"TqSftClcdInv\" … \"TpOilRotRetA\" \"TpOilRotR…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = matread(\"train_data.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e67c8d9-5e8d-4436-9319-ad6a317c378f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract data from dict\n",
    "\n",
    "U = data[\"U\"];\n",
    "X = data[\"X\"];\n",
    "Y = X;\n",
    "\n",
    "UNames = data[\"UNames\"];\n",
    "XNames = data[\"XNames\"];\n",
    "YNames = XNames;\n",
    "\n",
    "measurement_series = data[\"measurement_series\"];\n",
    "dt = data[\"dt\"];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc40d3c-fa9d-493e-bcc3-f02d5db48d30",
   "metadata": {},
   "source": [
    "### Data description:\n",
    "\n",
    "You are given a part of a dataset measured from an electric motor at Mercedes-Benz to examine its thermal properties. The dataset you are given consists of $594885$ measurement points, which are divided into $10$ independent series of measurement sessions. A short description of the different variables in the data is given in the following:\n",
    "\n",
    "---\n",
    "\n",
    "- ```data[\"U\"]``` contains a matrix with the shape $594885 \\times 21$. These are the $594885$ samples of the input vector $\\mathbf{u}(t) \\in \\mathbb{R}^{21}$ which can influence its thermal behavior. In detail these are\n",
    "    - $u_1$: rpm, rotations per minute of the motor shaft\n",
    "    - $u_2$: torque of the drive shaft\n",
    "    - $u_3$: absolute value of the torque of the drive shaft\n",
    "    - $u_4$: $i_d$ d-current\n",
    "    - $u_5$: $i_q$ q-current\n",
    "    - $u_6$: $\\| i_q \\|$\n",
    "    - $u_7$: root-mean-squared phase current\n",
    "    - $u_8$: $u_d$ d-voltage\n",
    "    - $u_{9}$: $\\| u_d \\|$ \n",
    "    - $u_{10}$: $u_q$ q-voltage\n",
    "    - $u_{11}$: neutral point displacement voltage\n",
    "    - $u_{12}$: inverter switching frequency\n",
    "    - $u_{13}$: DC link voltage\n",
    "    - $u_{14}$: modulation index\n",
    "    - $u_{15}$: power of the drive shaft\n",
    "    - $u_{16}$: oil flow rate for cooling of the rotor\n",
    "    - $u_{17}$: oil flow rate for cooling of the stator\n",
    "    - $u_{18}$: oil temperature at entry (rotor)\n",
    "    - $u_{19}$: oil temperature at entry (stator)\n",
    "    - $u_{20}$: oil temperature at exit A (rotor)\n",
    "    - $u_{21}$: oil temperature at exit B (rotor)\n",
    "- ```data[\"UNames\"]``` contains abbreviations for the different elements in $\\mathbf{u}(t)$, e.g. for plot labels\n",
    "- ```data[\"X\"]``` contains the state of the motor, which in this case is a stator and a rotor temperature. There are $594885$ samples of the state vector (target) $\\mathbf{x}(t) \\in \\mathbb{R}^{2}$.\n",
    "    - $x_1$: $T_{stat}$ stator temperature\n",
    "    - $x_2$: $T_{rot}$ rotor temperature\n",
    "- ```data[\"XNames\"]``` contains abbreviations for the different elements in $\\mathbf{x}(t)$, e.g. for plot labels\n",
    "- ```data[\"dt\"]``` contains the time between measurement points\n",
    "- ```data[\"measurement_series\"]``` contains a matrix with the shape $594885 \\times 1$. That assigns each measurement point to a measurement series, i.e. the $242856$-th element in this matrix is a $4$ which means that the $242856$-th measurement belongs to measurement series $4$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bc69f7-1b51-4087-95ad-6e990f959b56",
   "metadata": {},
   "source": [
    "**Hint 1:** What implication does the split into multiple measurement series have? Does it make sense to use all of the data at once?\n",
    "\n",
    "**Hint 2:** While you might not have access to the actual test data, is there a way to improve/test the generalization performance of your model?\n",
    "\n",
    "**Hint 3:** Through the  ```utils.jl```-file in the task folder you are given a set of minimal helper functions which you can use to get a feeling for the data and create some plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a84cbd-9ec7-4420-bc1e-ba5824dc8161",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "?plot_at_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fc42a7-0a29-475e-8022-5d0ed0117c8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p1 = plot(xlabel=L\"k\", ylabel=L\"u\");\n",
    "p1 = plot_at_idx(p1, U, measurement_series, UNames, measurement_series_idx=4, feature_idx=21) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e46eb9b-4c55-4f63-a2dc-de40242c746f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p2 = plot(xlabel=L\"k\", ylabel=L\"y\");\n",
    "p2 = plot_at_idx(p2, Y, measurement_series, XNames, measurement_series_idx=8, feature_idx=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af707d42-4e9d-4d59-89bb-c642ad3c7530",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p = plot_histogram(U, UNames, feature_idx=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c063f5b7-c2fa-473d-a4e9-58abc3f79a8f",
   "metadata": {},
   "source": [
    "### Create and fit your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577f4b23-04b6-41b0-b701-bfc19e43b1f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# REPLACE WITH YOUR CODE\n",
    "parameters = [2, 2, 5, 1]-\n",
    "\n",
    "if @isdefined parameters\n",
    "    serialize(\"final_task_parameters\", parameters)\n",
    "end\n",
    "# REPLACE WITH YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adc40cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_prep (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#functions for feature engg and data prep\n",
    "function feature_engg(u)\n",
    "    return u\n",
    "end\n",
    "\n",
    "function data_prep(U_raw, X_raw, measurement_series, series_indices, max_steps = nothing)\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for series_idx in series_indices\n",
    "        u_series = extract(U_raw, measurement_series, series_idx)\n",
    "        x_series = extract(X_raw, measurement_series, series_idx)\n",
    "\n",
    "        u_series = Float32.(u_series)\n",
    "        x_series = Float32.(x_series)\n",
    "\n",
    "        engineered_u = feature_engg(u_series)\n",
    "\n",
    "        input_data = permutedims(engineered_u, (2, 1))\n",
    "        target_data = permutedims(x_series, (2, 1))\n",
    "\n",
    "        if max_steps !== nothing\n",
    "            input_data = input_data[:, 1:max_steps]\n",
    "            target_data = target_data[:, 1:max_steps]\n",
    "        end\n",
    "\n",
    "        push!(inputs, input_data)\n",
    "        push!(targets, target_data)\n",
    "    end\n",
    "    return inputs, targets\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b85cddc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Any[Float32[499.98 500.01 … 500.06 499.96; 0.38744998 0.38839498 … 0.36970502 0.384195; … ; 74.67 74.67 … 74.57 74.57; 75.76 75.76 … 75.93 75.89], Float32[499.92 500.1 … 499.99 499.91; 0.38913 0.39753 … 0.355635 0.40194002; … ; 55.24 55.19 … 54.87 54.84; 55.08 55.05 … 54.73 54.71]], Any[Float32[77.68367 77.67987 … 77.66153 77.65891; 83.07999 83.08416 … 83.085884 83.08202], Float32[69.90183 69.90491 … 69.929955 69.93315; 85.22991 85.18944 … 84.90354 84.8472]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dividing the data\n",
    "training_series_indices = 1\n",
    "val_series_indices = 6\n",
    "test_series_indices = 9:10\n",
    "steps = 10\n",
    "\n",
    "# 1. First, get all data\n",
    "training_inputs, training_targets = data_prep(U, X, measurement_series, training_series_indices, steps)\n",
    "val_inputs, val_targets = data_prep(U, X, measurement_series, val_series_indices, steps)\n",
    "test_inputs, test_targets = data_prep(U, X, measurement_series, test_series_indices, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9c0ca0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Matrix{Float32}}:\n",
       " [-6.7888007 -7.107344 … -9.264978 -9.553661; -27.777664 -27.85833 … -28.471687 -28.675396]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Statistics\n",
    "\n",
    "all_training_inputs = hcat(training_inputs...)\n",
    "μ_input = mean(all_training_inputs, dims=2)\n",
    "σ_input = std(all_training_inputs, dims=2)\n",
    "\n",
    "all_training_targets = hcat(training_targets...)\n",
    "μ_target = mean(all_training_targets, dims=2)\n",
    "σ_target = std(all_training_targets, dims=2)\n",
    "\n",
    "normalize(data, μ, σ) = (data .- μ) ./ σ\n",
    "denormalize(data, μ, σ) = (data .* σ) .+ μ\n",
    "\n",
    "normalized_training_inputs = [normalize(x, μ_input, σ_input) for x in training_inputs]\n",
    "normalized_training_targets = [normalize(y, μ_target, σ_target) for y in training_targets]\n",
    "normalized_val_inputs = [normalize(x, μ_input, σ_input) for x in val_inputs]\n",
    "normalized_val_targets = [normalize(y, μ_target, σ_target) for y in val_targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd3fcec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Matrix{Float32}}:\n",
       " [-0.16422176 -0.17410736 … -0.24106672 -0.25002566; 0.73210436 0.73136234 … 0.7257203 0.72384644]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#new normalisation\n",
    "using Statistics\n",
    "\n",
    "all_training_inputs = hcat(training_inputs...)\n",
    "min_input = minimum(all_training_inputs)\n",
    "max_input = maximum(all_training_inputs)\n",
    "\n",
    "all_training_targets = hcat(training_targets...)\n",
    "min_target = minimum(all_training_targets)\n",
    "max_target = maximum(all_training_targets)\n",
    "\n",
    "normalize(data, min_val, max_val) = (data .- min_val) ./ (max_val .- min_val)\n",
    "denormalize(data, min_val, max_val) = (data .* (max_val .- min_val)) .+ min_val\n",
    "\n",
    "normalized_training_inputs = [normalize(x, min_input, max_input) for x in training_inputs]\n",
    "normalized_training_targets = [normalize(y, min_target, max_target) for y in training_targets]\n",
    "normalized_val_inputs = [normalize(x, min_input, max_input) for x in val_inputs]\n",
    "normalized_val_targets = [normalize(y, min_target, max_target) for y in val_targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5552280f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shapes:\n",
      "Sample 1: input size = (21, 20), target size = (2, 20)\n"
     ]
    }
   ],
   "source": [
    "unique(size(x, 1) for x in training_inputs)\n",
    "println(\"Training data shapes:\")\n",
    "for i in 1:length(training_inputs)\n",
    "    println(\"Sample $i: input size = \", size(training_inputs[i]), \", target size = \", size(training_targets[i]))\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8020096a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size: (21, 30)\n",
      "Sample target size: (2, 30)\n"
     ]
    },
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `model` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `model` not defined in `Main`\n",
      "Suggestion: check for spelling errors or missing imports.\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ d:\\ds4dsproject\\final_task_data_and_aux_files\\final_task\\jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X31sZmlsZQ==.jl:7"
     ]
    }
   ],
   "source": [
    "sample_input = training_inputs[1]\n",
    "sample_target = training_targets[1]\n",
    "\n",
    "println(\"Sample input size: \", size(sample_input))\n",
    "println(\"Sample target size: \", size(sample_target))\n",
    "\n",
    "Flux.reset!(model)\n",
    "output = model(sample_input[:, 1:2])  # Forward pass on first 2 timesteps\n",
    "\n",
    "println(\"Model output size: \", size(output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56efcd39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluate_model (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Flux, Flux.Optimise\n",
    "using Flux: params\n",
    "\n",
    "#model\n",
    "num_input_features = size(training_inputs[1], 1)\n",
    "num_output_features = size(training_targets[1], 1)\n",
    "\n",
    "hidden_size = 64\n",
    "model_lstm = Chain(\n",
    "    LSTM(num_input_features => hidden_size), \n",
    "    Dense(hidden_size, num_output_features)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "77531dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min value: 0.0\n",
      "Max value: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Check the min and max values of your training inputs\n",
    "min_val = minimum(minimum.(normalized_training_inputs))\n",
    "max_val = maximum(maximum.(normalized_training_inputs))\n",
    "println(\"Min value: \", min_val)\n",
    "println(\"Max value: \", max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a9d673c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Chain(\n",
       "    var\"#83#84\"(),\n",
       "    Conv((3,), 21 => 32, relu),         \u001b[90m# 2_048 parameters\u001b[39m\n",
       "    MaxPool((2,)),\n",
       "    Flux.flatten,\n",
       "  ),\n",
       "  Dense(128 => 2),                      \u001b[90m# 258 parameters\u001b[39m\n",
       ") \u001b[90m                  # Total: 4 arrays, \u001b[39m2_306 parameters, 9.289 KiB."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model (Part 1: The convolutional and pooling layers)\n",
    "cnn_layers = Chain(\n",
    "    # Correctly reshape and permute the input\n",
    "    x -> PermutedDimsArray(reshape(x, size(x, 1), size(x, 2), 1), (2, 1, 3)),\n",
    "    Conv((3,), num_input_features => 32, relu),\n",
    "    MaxPool((2,)),\n",
    "    Flux.flatten\n",
    ")\n",
    "\n",
    "# Get the size of the flattened output\n",
    "sample_input = normalized_training_inputs[1]\n",
    "flattened_size = size(cnn_layers(sample_input), 1)\n",
    "\n",
    "# Model (Part 2: The full model)\n",
    "model_cnn = Chain(\n",
    "    cnn_layers,\n",
    "    # The Dense layer is now dynamic\n",
    "    Dense(flattened_size, num_output_features)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9743f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluate_model (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hyperparamters\n",
    "#model\n",
    "model = model_cnn\n",
    "\n",
    "#loss\n",
    "mse(predicted, target) = mean(abs2, predicted .- target)\n",
    "\n",
    "#optimizer\n",
    "learning_rate = 0.00001\n",
    "optimizer = Flux.setup(ADAM(learning_rate), model)\n",
    "\n",
    "#epochs\n",
    "epochs = 10\n",
    "\n",
    "#eval\n",
    "function evaluate_model(model, inputs, targets)\n",
    "    total_loss = 0.0\n",
    "    for (input, target) in zip(inputs, targets)\n",
    "        Flux.reset!(model)\n",
    "        predicted_normalized = model(input)\n",
    "        predicted_denormalized = denormalize(predicted_normalized, min_target, max_target)\n",
    "        total_loss += mse(predicted_denormalized, denormalize(target, min_target, max_target))\n",
    "\n",
    "    end\n",
    "    return total_loss / length(inputs)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a372e097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: NaN, Validation Loss: NaN\n",
      "Epoch 2, Training Loss: NaN, Validation Loss: NaN\n",
      "Epoch 3, Training Loss: NaN, Validation Loss: NaN\n",
      "Epoch 4, Training Loss: NaN, Validation Loss: NaN\n",
      "Epoch 5, Training Loss: NaN, Validation Loss: NaN\n",
      "Epoch 6, Training Loss: NaN, Validation Loss: NaN\n",
      "Epoch 7, Training Loss: NaN, Validation Loss: NaN\n",
      "Epoch 8, Training Loss: NaN, Validation Loss: NaN\n",
      "Epoch 9, Training Loss: NaN, Validation Loss: NaN\n",
      "Epoch 10, Training Loss: NaN, Validation Loss: NaN\n"
     ]
    }
   ],
   "source": [
    "# Corrected training loop\n",
    "function train_model!(model, optimizer, opt_state, epochs, training_inputs, training_targets, val_inputs, val_targets)\n",
    "    for epoch in 1:epochs\n",
    "        for (inputs, targets) in zip(training_inputs, training_targets)\n",
    "            # Reset the model's state at the start of each new sequence\n",
    "            Flux.reset!(model)\n",
    "\n",
    "            # Use `withgradient` for a more efficient way to get loss and gradients\n",
    "            loss, grads = Flux.withgradient(model) do m\n",
    "                predicted_traj = m(inputs)\n",
    "                mse(predicted_traj, targets)\n",
    "            end\n",
    "\n",
    "            # Update the model and the optimizer state with the new gradients\n",
    "            Flux.update!(opt_state, model, grads[1])\n",
    "        end\n",
    "\n",
    "        train_loss = evaluate_model(model, training_inputs, training_targets)\n",
    "        validation_loss = evaluate_model(model, val_inputs, val_targets)\n",
    "        \n",
    "        println(\"Epoch $epoch, Training Loss: $train_loss, Validation Loss: $validation_loss\")\n",
    "    end\n",
    "end\n",
    "\n",
    "train_model!(model, optimizer, optimizer, epochs, normalized_training_inputs, normalized_training_targets, normalized_val_inputs, normalized_val_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2d351d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test Loss: 2.440201875e6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `Flux.params(m...)` is deprecated. Use `Flux.trainable(model)` for parameter collection,\n",
      "│ and the explicit `gradient(m -> loss(m, x, y), model)` for gradient computation.\n",
      "└ @ Flux C:\\Users\\Admin\\.julia\\packages\\Flux\\BkG8S\\src\\deprecations.jl:93\n"
     ]
    }
   ],
   "source": [
    "final_model = model\n",
    "\n",
    "test_loss = evaluate_model(final_model, test_inputs, test_targets)\n",
    "println(\"Final test Loss: $test_loss\")\n",
    "\n",
    "serialize(\"final_task_parameters\", params(final_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb93b368-0665-45fc-a72c-80a370dcaec5",
   "metadata": {},
   "source": [
    "### Saving your model for evaluation:\n",
    "\n",
    "After you have finished your model, we will evaluate its performance on the test dataset. To do so we will need to be able to make a forward pass with your model and we will need you to give us your model parameters.\n",
    "\n",
    "- fill out the function given in ```model_forward_pass.jl```\n",
    "- store your parameters in a file named ```final_task_parameters```\n",
    "\n",
    "```\n",
    "# Example code for storing parameters:\n",
    "\n",
    "if @isdefined parameters\n",
    "    serialize(\"final_task_parameters\", parameters)\n",
    "end\n",
    "```\n",
    "\n",
    "You can use the code below on the training to check if your result can be read properly **(If you run into problems with this or if your forward pass needs extra inputs, please contact us)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3f9fe7-0072-416d-8862-6575b588a7f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "include(\"model_forward_pass.jl\");\n",
    "using .ModelForwardPass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ca0ee1-875d-4ae8-bb8d-d7178374cb7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "?ModelForwardPass.your_model_forward_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3598ff1-48bd-4cd3-87b6-6c94d46e09d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters_evaluation = deserialize(\"final_task_parameters\");\n",
    "\n",
    "measurement_series_idx = 1\n",
    "\n",
    "_u = extract(U, measurement_series, measurement_series_idx);\n",
    "_target = extract(X, measurement_series, measurement_series_idx);\n",
    "_x0 = _target[1, :];\n",
    "\n",
    "tsteps = collect(0:0.5:(size(_u, 1) * 0.5));\n",
    "\n",
    "predicted_trajectory = ModelForwardPass.your_model_forward_pass(\n",
    "    inputs=_u,\n",
    "    x0=_x0,\n",
    "    parameters=parameters_evaluation,\n",
    "    tsteps=tsteps\n",
    ");\n",
    "\n",
    "println(\"MSE: \", StatsBase.mean((_target - predicted_trajectory).^2))\n",
    "\n",
    "p_eval = plot(xlabel=L\"k\", ylabel=L\"x\")\n",
    "\n",
    "p_eval = plot_at_idx(p_eval, X, measurement_series, XNames, measurement_series_idx=measurement_series_idx, feature_idx=1)\n",
    "p_eval = plot!(p_eval, predicted_trajectory[:, 1], label=L\"\\hat{x}_1\")\n",
    "\n",
    "display(p_eval)\n",
    "\n",
    "p_eval = plot(xlabel=L\"k\", ylabel=L\"x\")\n",
    "\n",
    "p_eval = plot_at_idx(p_eval, X, measurement_series, XNames, measurement_series_idx=measurement_series_idx, feature_idx=2)\n",
    "p_eval = plot!(p_eval, predicted_trajectory[:, 2], label=L\"\\hat{x}_2\")\n",
    "\n",
    "display(p_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3cf9a9-c00b-4e5a-9d01-f453aae9b421",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.0",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
